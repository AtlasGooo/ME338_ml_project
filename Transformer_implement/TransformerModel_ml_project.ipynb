{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch import Tensor\n",
    "\n",
    "import torchtext\n",
    "from torchtext.legacy.datasets import Multi30k\n",
    "from torchtext.legacy.data import Field, BucketIterator\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.ticker as ticker\n",
    "\n",
    "import spacy\n",
    "import numpy as np\n",
    "\n",
    "import random\n",
    "import math\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "### (PARAMS)\n",
    "SEED = 1234\n",
    "\n",
    "random.seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "torch.manual_seed(SEED)\n",
    "torch.cuda.manual_seed(SEED)\n",
    "torch.backends.cudnn.deterministic = True\n",
    "\n",
    "spacy_de = spacy.load('de_core_news_sm')\n",
    "spacy_en = spacy.load('en_core_web_sm')\n",
    "\n",
    "DEVICE = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "# DEVICE = torch.device('cpu')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def tokenize_de(text):\n",
    "    \"\"\"\n",
    "    Tokenizes German text from a string into a list of strings\n",
    "    \"\"\"\n",
    "    return [tok.text for tok in spacy_de.tokenizer(text)]\n",
    "\n",
    "def tokenize_en(text):\n",
    "    \"\"\"\n",
    "    Tokenizes English text from a string into a list of strings\n",
    "    \"\"\"\n",
    "    return [tok.text for tok in spacy_en.tokenizer(text)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "SRC = Field(tokenize = tokenize_de, \n",
    "            init_token = '<sos>', \n",
    "            eos_token = '<eos>', \n",
    "            lower = True, \n",
    "            batch_first = False)\n",
    "\n",
    "TRG = Field(tokenize = tokenize_en, \n",
    "            init_token = '<sos>', \n",
    "            eos_token = '<eos>', \n",
    "            lower = True, \n",
    "            batch_first = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_data, valid_data, test_data = Multi30k.splits(exts = ('.de', '.en'), \n",
    "                                                    fields = (SRC, TRG))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true,
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'list'>\n",
      "train_data\n",
      "['ein', 'mann', 'in', 'einem', 'blauen', 'hemd', 'steht', 'auf', 'einer', 'leiter', 'und', 'putzt', 'ein', 'fenster', '.']\n",
      "['a', 'man', 'in', 'a', 'blue', 'shirt', 'is', 'standing', 'on', 'a', 'ladder', 'cleaning', 'a', 'window', '.']\n",
      "\n",
      "valid_data\n",
      "['zwei', 'm채nner', 'bauen', 'eine', 'blaue', 'eisfischerh체tte', 'auf', 'einem', 'zugefrorenen', 'see', 'auf']\n",
      "['two', 'men', 'setting', 'up', 'a', 'blue', 'ice', 'fishing', 'hut', 'on', 'an', 'iced', 'over', 'lake']\n",
      "\n",
      "test_data\n",
      "['f체nf', 'leute', 'in', 'winterjacken', 'und', 'mit', 'helmen', 'stehen', 'im', 'schnee', 'mit', 'schneemobilen', 'im', 'hintergrund', '.']\n",
      "['five', 'people', 'wearing', 'winter', 'jackets', 'and', 'helmets', 'stand', 'in', 'the', 'snow', ',', 'with', 'snowmobiles', 'in', 'the', 'background', '.']\n",
      "\n"
     ]
    }
   ],
   "source": [
    "### (TEST)\n",
    "test_index = 3\n",
    "print(type(train_data.examples))\n",
    "print(\"train_data\")\n",
    "print(vars(train_data.examples[test_index])['src'])\n",
    "print(vars(train_data.examples[test_index])['trg'])\n",
    "print(\"\")\n",
    "\n",
    "print(\"valid_data\")\n",
    "print(vars(valid_data.examples[test_index])['src'])\n",
    "print(vars(valid_data.examples[test_index])['trg'])\n",
    "print(\"\")\n",
    "\n",
    "print(\"test_data\")\n",
    "print(vars(test_data.examples[test_index])['src'])\n",
    "print(vars(test_data.examples[test_index])['trg'])\n",
    "print(\"\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "### (lzj)\n",
    "# SRC.build_vocab(train_data, min_freq = 2)\n",
    "# TRG.build_vocab(train_data, min_freq = 2)\n",
    "SRC.build_vocab(train_data)\n",
    "TRG.build_vocab(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true,
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18668\n",
      "9799\n"
     ]
    }
   ],
   "source": [
    "### (TEST)\n",
    "print(len(SRC.vocab))\n",
    "print(len(TRG.vocab))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "### (lzj)\n",
    "### (PARAMS)\n",
    "BATCH_SIZE = 32\n",
    "\n",
    "train_iterator, valid_iterator, test_iterator = BucketIterator.splits(\n",
    "    (train_data, valid_data, test_data), \n",
    "     batch_size = BATCH_SIZE,\n",
    "     device = DEVICE)\n",
    "\n",
    "# batch.src / batch.trg : [N,S]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true,
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "i = 0\n",
      "src.shape: torch.Size([22, 32])\n",
      "trg.shape: torch.Size([28, 32])\n",
      "\n",
      "src[:,:3]: tensor([[    2,     2,     2],\n",
      "        [   18,     5,    18],\n",
      "        [ 4706,    13,    54],\n",
      "        [   57,    11,    52],\n",
      "        [    5,     6,   100],\n",
      "        [  318,   713,     6],\n",
      "        [    4,    95, 18255],\n",
      "        [    3,    23,    27],\n",
      "        [    1,    17,    14],\n",
      "        [    1, 15182,   189],\n",
      "        [    1,     7,     4],\n",
      "        [    1,     6,     3],\n",
      "        [    1, 16887,     1],\n",
      "        [    1,    21,     1],\n",
      "        [    1,     4,     1],\n",
      "        [    1,     3,     1],\n",
      "        [    1,     1,     1],\n",
      "        [    1,     1,     1],\n",
      "        [    1,     1,     1],\n",
      "        [    1,     1,     1],\n",
      "        [    1,     1,     1],\n",
      "        [    1,     1,     1]], device='cuda:0')\n",
      "src[:,-3:]: tensor([[    2,     2,     2],\n",
      "        [    5,    18,     8],\n",
      "        [   66,     7,    36],\n",
      "        [   25, 12909,    73],\n",
      "        [   60,   196,    60],\n",
      "        [   21,    26,    21],\n",
      "        [    6,    30,    14],\n",
      "        [  365,   711,  3804],\n",
      "        [  200,    19,    14],\n",
      "        [   11,  3238,  4176],\n",
      "        [  332,   366,   117],\n",
      "        [   19,     8,     4],\n",
      "        [  567,    34,     3],\n",
      "        [   72,    72,     1],\n",
      "        [    4,    10,     1],\n",
      "        [    3,    55,     1],\n",
      "        [    1,   639,     1],\n",
      "        [    1,    52,     1],\n",
      "        [    1,   389,     1],\n",
      "        [    1,     4,     1],\n",
      "        [    1,     3,     1],\n",
      "        [    1,     1,     1]], device='cuda:0')\n",
      "\n",
      "trg[:,:3]: tensor([[   2,    2,    2],\n",
      "        [  16,    4,   16],\n",
      "        [ 639,    9,   19],\n",
      "        [  12,   13,  100],\n",
      "        [ 353,    4,  236],\n",
      "        [ 215,  332,    4],\n",
      "        [  37,  271,  108],\n",
      "        [   4,   10,  376],\n",
      "        [ 135, 1740,    4],\n",
      "        [   5,    7, 2085],\n",
      "        [   3, 3188,    5],\n",
      "        [   1,    6,    3],\n",
      "        [   1,    4,    1],\n",
      "        [   1, 2605,    1],\n",
      "        [   1, 1609,    1],\n",
      "        [   1,    5,    1],\n",
      "        [   1,    3,    1],\n",
      "        [   1,    1,    1],\n",
      "        [   1,    1,    1],\n",
      "        [   1,    1,    1],\n",
      "        [   1,    1,    1],\n",
      "        [   1,    1,    1],\n",
      "        [   1,    1,    1],\n",
      "        [   1,    1,    1],\n",
      "        [   1,    1,    1],\n",
      "        [   1,    1,    1],\n",
      "        [   1,    1,    1],\n",
      "        [   1,    1,    1]], device='cuda:0')\n",
      "trg[:,-3:]: tensor([[   2,    2,    2],\n",
      "        [   4,   16,    4],\n",
      "        [  53,   24,   38],\n",
      "        [  33,   30,   12],\n",
      "        [  45,   22,   19],\n",
      "        [ 367, 2188,  673],\n",
      "        [  10, 3172,   49],\n",
      "        [  41, 1289,    4],\n",
      "        [ 368,    4,  354],\n",
      "        [  40, 1189,  481],\n",
      "        [   4,  271,    5],\n",
      "        [ 288,   40,    3],\n",
      "        [   8,    4,    1],\n",
      "        [   4,   39,    1],\n",
      "        [ 396,  582,    1],\n",
      "        [ 184,  201,    1],\n",
      "        [   5,    8,    1],\n",
      "        [   3,    7,    1],\n",
      "        [   1,  156,    1],\n",
      "        [   1,   12,    1],\n",
      "        [   1,    7,    1],\n",
      "        [   1,   39,    1],\n",
      "        [   1,    5,    1],\n",
      "        [   1,    3,    1],\n",
      "        [   1,    1,    1],\n",
      "        [   1,    1,    1],\n",
      "        [   1,    1,    1],\n",
      "        [   1,    1,    1]], device='cuda:0')\n",
      "\n",
      "i = 1\n",
      "src.shape: torch.Size([23, 32])\n",
      "trg.shape: torch.Size([25, 32])\n",
      "\n",
      "src[:,:3]: tensor([[   2,    2,    2],\n",
      "        [  17,   18,   18],\n",
      "        [2007,   30,   45],\n",
      "        [  14,   52,    7],\n",
      "        [2984,  497, 1413],\n",
      "        [  16,   44,   74],\n",
      "        [   9,  362,  133],\n",
      "        [  17,    4,   17],\n",
      "        [  11,    3,   34],\n",
      "        [  15,    1,   72],\n",
      "        [ 507,    1,    3],\n",
      "        [  62,    1,    1],\n",
      "        [   4,    1,    1],\n",
      "        [   3,    1,    1],\n",
      "        [   1,    1,    1],\n",
      "        [   1,    1,    1],\n",
      "        [   1,    1,    1],\n",
      "        [   1,    1,    1],\n",
      "        [   1,    1,    1],\n",
      "        [   1,    1,    1],\n",
      "        [   1,    1,    1],\n",
      "        [   1,    1,    1],\n",
      "        [   1,    1,    1]], device='cuda:0')\n",
      "src[:,-3:]: tensor([[    2,     2,     2],\n",
      "        [    5,     8,    18],\n",
      "        [  777,    16,  1280],\n",
      "        [ 1051,    83,   500],\n",
      "        [  846,    55,    42],\n",
      "        [ 1292,    91,    75],\n",
      "        [   22,     6,     4],\n",
      "        [   18,    49,     3],\n",
      "        [ 2027,  1034,     1],\n",
      "        [   11,     4,     1],\n",
      "        [    6,     3,     1],\n",
      "        [13949,     1,     1],\n",
      "        [    9,     1,     1],\n",
      "        [   35,     1,     1],\n",
      "        [    5,     1,     1],\n",
      "        [  116,     1,     1],\n",
      "        [   10,     1,     1],\n",
      "        [    5,     1,     1],\n",
      "        [  777,     1,     1],\n",
      "        [ 4930,     1,     1],\n",
      "        [  399,     1,     1],\n",
      "        [    4,     1,     1],\n",
      "        [    3,     1,     1]], device='cuda:0')\n",
      "\n",
      "trg[:,:3]: tensor([[   2,    2,    2],\n",
      "        [ 182,   16,   16],\n",
      "        [  12,   30,   14],\n",
      "        [   4,   36,   22],\n",
      "        [  31,   57, 1066],\n",
      "        [  42,   71,   41],\n",
      "        [ 210,   18,   40],\n",
      "        [  14,    4,    7],\n",
      "        [  78,   77,   39],\n",
      "        [   8,    5,  129],\n",
      "        [   7,    3,    3],\n",
      "        [ 354,    1,    1],\n",
      "        [   5,    1,    1],\n",
      "        [   3,    1,    1],\n",
      "        [   1,    1,    1],\n",
      "        [   1,    1,    1],\n",
      "        [   1,    1,    1],\n",
      "        [   1,    1,    1],\n",
      "        [   1,    1,    1],\n",
      "        [   1,    1,    1],\n",
      "        [   1,    1,    1],\n",
      "        [   1,    1,    1],\n",
      "        [   1,    1,    1],\n",
      "        [   1,    1,    1],\n",
      "        [   1,    1,    1]], device='cuda:0')\n",
      "trg[:,-3:]: tensor([[   2,    2,    2],\n",
      "        [   4,    4,   16],\n",
      "        [ 161,   14, 1553],\n",
      "        [  39,   79,  252],\n",
      "        [ 915,  376,    4],\n",
      "        [2027,    4, 1056],\n",
      "        [   4,   55,    3],\n",
      "        [2102,    8,    1],\n",
      "        [ 941,    7,    1],\n",
      "        [ 195,   88,    1],\n",
      "        [  16,    5,    1],\n",
      "        [ 758,    3,    1],\n",
      "        [  15,    1,    1],\n",
      "        [  28,    1,    1],\n",
      "        [   4,    1,    1],\n",
      "        [ 154,    1,    1],\n",
      "        [  11,    1,    1],\n",
      "        [   4,    1,    1],\n",
      "        [ 161,    1,    1],\n",
      "        [3135,    1,    1],\n",
      "        [  15,    1,    1],\n",
      "        [ 214,    1,    1],\n",
      "        [   8,    1,    1],\n",
      "        [   5,    1,    1],\n",
      "        [   3,    1,    1]], device='cuda:0')\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "### (TEST) generate correct form of data\n",
    "for i,batch in enumerate(train_iterator):\n",
    "    if i < 2 :\n",
    "        print(f'i = {i}')\n",
    "        src = batch.src\n",
    "        trg = batch.trg\n",
    "        print(f'src.shape: {src.shape}')\n",
    "        print(f'trg.shape: {trg.shape}')\n",
    "        print(\"\")\n",
    "        \n",
    "        print(f'src[:,:3]: {src[:,:3]}')\n",
    "        print(f'src[:,-3:]: {src[:,-3:]}')  \n",
    "        print(\"\")\n",
    "        \n",
    "        print(f'trg[:,:3]: {trg[:,:3]}')\n",
    "        print(f'trg[:,-3:]: {trg[:,-3:]}')        \n",
    "        \n",
    "#         src = torch.unsqueeze(src, dim = 0)\n",
    "#         trg = torch.unsqueeze(trg, dim = 0)\n",
    "#         print(f'src.shape: {src.shape}')\n",
    "#         print(f'trg.shape: {trg.shape}')\n",
    "#         print(f'src: {src[:,:3,:]}')    \n",
    "#         print(f'trg: {trg[:,:3,:]}')        \n",
    "        \n",
    "        print(\"\")  \n",
    "    else:\n",
    "        break\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "SRC_PAD = SRC.pad_token\n",
    "SRC_PAD_INIT = SRC.init_token\n",
    "SRC_PAD_EOS = SRC.eos_token\n",
    "\n",
    "SRC_PAD_IDX = SRC.vocab.stoi[SRC_PAD]\n",
    "SRC_PAD_INIT_IDX = SRC.vocab.stoi[SRC_PAD_INIT]\n",
    "SRC_PAD_EOS_IDX = SRC.vocab.stoi[SRC_PAD_EOS]\n",
    "\n",
    "TRG_PAD = TRG.pad_token\n",
    "TRG_PAD_INIT = TRG.init_token\n",
    "TRG_PAD_EOS = TRG.eos_token\n",
    "\n",
    "TRG_PAD_IDX = TRG.vocab.stoi[TRG_PAD]\n",
    "TRG_PAD_INIT_IDX = SRC.vocab.stoi[TRG_PAD_INIT]\n",
    "TRG_PAD_EOS_IDX = SRC.vocab.stoi[TRG_PAD_EOS]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# ### (TEST)\n",
    "# print(f'SRC_PAD: {SRC_PAD}')\n",
    "# print(f'SRC_PAD_INIT: {SRC_PAD_INIT}')\n",
    "# print(f'SRC_PAD_EOS: {SRC_PAD_EOS}')\n",
    "# print(\"\")\n",
    "\n",
    "# print(f'SRC_PAD_IDX: {SRC_PAD_IDX}')\n",
    "# print(f'SRC_PAD_INIT_IDX: {SRC_PAD_INIT_IDX}')\n",
    "# print(f'SRC_PAD_EOS_IDX: {SRC_PAD_EOS_IDX}')\n",
    "# print(\"\")\n",
    "\n",
    "# print(f'TRG_PAD: {TRG_PAD}')\n",
    "# print(f'TRG_PAD_INIT: {TRG_PAD_INIT}')\n",
    "# print(f'TRG_PAD_EOS: {TRG_PAD_EOS}')\n",
    "# print(\"\")\n",
    "\n",
    "# print(f'TRG_PAD_IDX: {TRG_PAD_IDX}')\n",
    "# print(f'TRG_PAD_INIT_IDX: {TRG_PAD_INIT_IDX}')\n",
    "# print(f'TRG_PAD_EOS_IDX: {TRG_PAD_EOS_IDX}')\n",
    "# print(\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TransformerModel Class "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.nn import Transformer,TransformerEncoder,TransformerDecoder,\\\n",
    "TransformerEncoderLayer,TransformerDecoderLayer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TransformerModel(nn.Module):\n",
    "    def __init__(self,\n",
    "                input_dim,\n",
    "                output_dim,\n",
    "                n_head,\n",
    "                hid_dim,\n",
    "                n_encoder_layer,\n",
    "                n_decoder_layer,\n",
    "                ff_dim,\n",
    "                dropout,\n",
    "                device,\n",
    "                max_len = 200):\n",
    "        super(TransformerModel,self).__init__()\n",
    "        self.device = device\n",
    "        self.hid_dim = hid_dim\n",
    "        \n",
    "        ## self layers \n",
    "        encoder_norm = nn.LayerNorm(hid_dim)  \n",
    "        decoder_norm = nn.LayerNorm(hid_dim)  \n",
    "        \n",
    "        encoder_layer = TransformerEncoderLayer(d_model=hid_dim, nhead=n_head,\n",
    "                                                dim_feedforward=ff_dim)\n",
    "\n",
    "        self.transformer_encoder = TransformerEncoder(encoder_layer, n_encoder_layer)\n",
    "        \n",
    "        decoder_layer = TransformerDecoderLayer(d_model=hid_dim, nhead=n_head,\n",
    "                                                dim_feedforward=ff_dim)\n",
    "        self.transformer_decoder = TransformerDecoder(decoder_layer, n_decoder_layer)\n",
    "              \n",
    "        self.src_tok_emb = TokenEmbedding(input_dim,hid_dim).to(device)\n",
    "        self.trg_tok_emb = TokenEmbedding(output_dim,hid_dim).to(device)\n",
    "        self.pos_emb = PositionalEncoding(hid_dim,dropout=dropout).to(device)\n",
    "        \n",
    "        self.out_linear = nn.Linear(hid_dim,output_dim).to(device)\n",
    "        \n",
    "    def forward(self,src,trg,src_attn_mask,trg_attn_mask,\n",
    "                src_pad_mask,trg_pad_mask,memory_pad_mask,\n",
    "                enable_test = False):\n",
    "        # src: [S,N]\n",
    "        # trg: [T,N]\n",
    "                                \n",
    "        N = src.shape[1]\n",
    "        S = src.shape[0]\n",
    "        T = trg.shape[0]\n",
    "    \n",
    "        # [S,N,E],[T,N,E]\n",
    "        src_emb = self.pos_emb(self.src_tok_emb(src))\n",
    "        trg_emb = self.pos_emb(self.trg_tok_emb(trg))        \n",
    "            \n",
    "        memory = self.transformer_encoder(src_emb, src_attn_mask, src_pad_mask)   \n",
    "            \n",
    "        # [T,N,E]        \n",
    "        output = self.transformer_decoder(trg_emb, memory, trg_attn_mask, None,\n",
    "                                        trg_pad_mask, memory_pad_mask )        \n",
    "        # [T,N,out_dim]\n",
    "        output = \\\n",
    "            self.out_linear(output).to(self.device)\n",
    "             \n",
    "        return output\n",
    "                 \n",
    "        \n",
    "    def create_trg_attn_mask(self,sz):\n",
    "        mask = (torch.triu(torch.ones((sz, sz), device=DEVICE)) == 1).transpose(0, 1)\n",
    "        mask = mask.float().masked_fill(mask == 0, float('-inf')).masked_fill(mask == 1, float(0.0))\n",
    "        return mask      \n",
    "    \n",
    "    def create_mask(self,src:Tensor, trg:Tensor): \n",
    "        # src: [S,N]\n",
    "        # trg: [T,N]\n",
    "        S = src.shape[0]\n",
    "        T = trg.shape[0]\n",
    "\n",
    "        # [S,S],[T,T]\n",
    "        src_attn_mask = torch.zeros((S,S), device = DEVICE).type(torch.bool)\n",
    "        trg_attn_mask = self.create_trg_attn_mask(T).to(self.device)\n",
    "\n",
    "        # [N,S],[N,T]\n",
    "        src_pad_mask = (src == SRC_PAD_IDX).transpose(0,1).to(self.device)\n",
    "        trg_pad_mask = (trg == TRG_PAD_IDX).transpose(0,1).to(self.device)\n",
    "\n",
    "        return src_attn_mask,src_pad_mask,trg_attn_mask,trg_pad_mask\n",
    "    \n",
    "    \n",
    "    def encode(self,src,src_attn_mask):\n",
    "        # src: [S,N]\n",
    "        # return: []\n",
    "        return self.transformer_encoder(self.pos_emb(self.src_tok_emb(src)),src_attn_mask)\n",
    "    \n",
    "    def decode(self,trg,memory,trg_attn_mask):\n",
    "        # trg: [T,N]\n",
    "        # return [T,N,E]\n",
    "        return self.transformer_decoder(self.pos_emb(self.trg_tok_emb(trg)),memory,trg_attn_mask)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PositionalEncoding(nn.Module):\n",
    "    def __init__(self, emb_size: int, dropout, maxlen: int = 5000):\n",
    "        super(PositionalEncoding, self).__init__()\n",
    "        den = torch.exp(- torch.arange(0, emb_size, 2) * math.log(10000) / emb_size)\n",
    "        pos = torch.arange(0, maxlen).reshape(maxlen, 1)\n",
    "        pos_embedding = torch.zeros((maxlen, emb_size))\n",
    "        pos_embedding[:, 0::2] = torch.sin(pos * den)\n",
    "        pos_embedding[:, 1::2] = torch.cos(pos * den)\n",
    "        pos_embedding = pos_embedding.unsqueeze(-2)\n",
    "\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        self.register_buffer('pos_embedding', pos_embedding)\n",
    "\n",
    "    def forward(self, token_embedding: Tensor):\n",
    "        return self.dropout(token_embedding + \n",
    "                            self.pos_embedding[:token_embedding.size(0),:])\n",
    "\n",
    "class TokenEmbedding(nn.Module):\n",
    "    def __init__(self, vocab_size: int, emb_size):\n",
    "        super(TokenEmbedding, self).__init__()\n",
    "        self.embedding = nn.Embedding(vocab_size, emb_size)\n",
    "        self.emb_size = emb_size\n",
    "    def forward(self, tokens: Tensor):\n",
    "        return self.embedding(tokens.long()) * math.sqrt(self.emb_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating TransformerModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "### (PARAMS)\n",
    "INPUT_DIM = len(SRC.vocab)\n",
    "OUTPUT_DIM = len(TRG.vocab)\n",
    "\n",
    "HEAD = 8\n",
    "HID_DIM = 256\n",
    "ENC_LAYER = 3\n",
    "DEC_LAYER = 3\n",
    "FF_DIM = 512\n",
    "DROPOUT = 0.1\n",
    "\n",
    "model = TransformerModel(\n",
    "                input_dim = INPUT_DIM,\n",
    "                output_dim = OUTPUT_DIM,\n",
    "                n_head = HEAD,\n",
    "                hid_dim = HID_DIM,\n",
    "                n_encoder_layer = ENC_LAYER,\n",
    "                n_decoder_layer = DEC_LAYER,\n",
    "                ff_dim = FF_DIM,\n",
    "                dropout = DROPOUT,\n",
    "                device = DEVICE,\n",
    "                max_len = 200)\n",
    "\n",
    "for p in model.parameters():\n",
    "    if p.dim() > 1:\n",
    "        nn.init.xavier_uniform_(p)\n",
    "        \n",
    "model = model.to(DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18668\n",
      "9799\n"
     ]
    }
   ],
   "source": [
    "print(INPUT_DIM)\n",
    "print(OUTPUT_DIM)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NoamOpt:\n",
    "    \"Optim wrapper that implements rate.\"\n",
    "    def __init__(self, model_size, factor, warmup, optimizer):\n",
    "        self.optimizer = optimizer\n",
    "        self._step = 0\n",
    "        self.warmup = warmup\n",
    "        self.factor = factor\n",
    "        self.model_size = model_size\n",
    "        self._rate = 0  \n",
    "        \n",
    "    def step(self):\n",
    "        \"Update parameters and rate\"\n",
    "        self._step += 1\n",
    "        rate = self.rate()\n",
    "        for p in self.optimizer.param_groups:\n",
    "            p['lr'] = rate\n",
    "        self._rate = rate\n",
    "        self.optimizer.step()   \n",
    "        \n",
    "    def rate(self, step = None):\n",
    "        \"Implement `lrate` above\"\n",
    "        if step is None:\n",
    "            step = self._step\n",
    "        return self.factor * \\\n",
    "            (self.model_size ** (-0.5) *\n",
    "            min(step ** (-0.5), step * self.warmup ** (-1.5)))\n",
    "    \n",
    "    def zero_grad(self):\n",
    "        return self.optimizer.zero_grad()\n",
    "    \n",
    "def get_std_opt(model):\n",
    "    return NoamOpt(model.hid_dim, 2, 4000,\n",
    "            torch.optim.Adam(model.parameters(), lr=0, betas=(0.9, 0.98), eps=1e-9))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "### (PARAMS)\n",
    "LEARNING_RATE = 0.0005\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr = LEARNING_RATE)\n",
    "# optimizer = NoamOpt(model.hid_dim, 1, 400,\n",
    "#         torch.optim.Adam(model.parameters(), lr=0, betas=(0.9, 0.98), eps=1e-9))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating loss fcn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss(ignore_index = TRG_PAD_IDX).to(DEVICE)\n",
    "# criterion = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Trainning & Testing\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train fcn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "### (PARAMS)\n",
    "enable_test = False\n",
    "\n",
    "def train_epoch(model, iterator, optimizer, criterion, max_norm):\n",
    "    model.train()\n",
    "    losses = 0.0\n",
    "    \n",
    "    for i,batch in enumerate(iterator):   \n",
    "        # [S,N],[T,N]\n",
    "        src = batch.src.to(DEVICE)\n",
    "        trg = batch.trg.to(DEVICE)\n",
    "        \n",
    "        ### (TODO) below: trg -> trg_input,trg_output\n",
    "        trg_input = trg[:-1,:]\n",
    "        \n",
    "        src_attn_mask,src_pad_mask,trg_attn_mask,trg_pad_mask = \\\n",
    "                                model.create_mask(src,trg_input)  \n",
    "     \n",
    "        out = model(src,trg_input,src_attn_mask,trg_attn_mask,src_pad_mask,trg_pad_mask,src_pad_mask)\n",
    "        out_E = out.shape[-1] \n",
    "        \n",
    "        optimizer.zero_grad()   \n",
    "        \n",
    "        out = out.contiguous().view(-1,out_E)\n",
    "        trg_output = trg[1:,:]        \n",
    "        trg_output = trg_output.contiguous().view(-1)\n",
    "       \n",
    "        loss = criterion(out,trg_output)\n",
    "        loss.backward()\n",
    "        \n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(),max_norm)\n",
    "        optimizer.step()\n",
    "        \n",
    "        losses += loss.item()\n",
    "        \n",
    "\n",
    "        ### (TEST)\n",
    "        if(enable_test and i%200==0):\n",
    "            print(f'in train_epoch(): loss={loss.item()} \\t losses={losses} \\t len(iterator)={len(iterator)} \\n')\n",
    "\n",
    "    return losses / len(iterator)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate fcn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def eval_epoch(model, iterator, criterion):\n",
    "    model.eval()\n",
    "    losses = 0.0\n",
    "\n",
    "    with torch.no_grad():    \n",
    "        for i,batch in enumerate(iterator):          \n",
    "            \n",
    "            src = batch.src.to(DEVICE)\n",
    "            trg = batch.trg.to(DEVICE) \n",
    "    \n",
    "            ### (TODO) below: trg -> trg_input,trg_output\n",
    "            trg_input = trg[:-1,:]\n",
    "            \n",
    "            src_attn_mask,src_pad_mask,trg_attn_mask,trg_pad_mask = \\\n",
    "                                    model.create_mask(src,trg_input)  \n",
    "\n",
    "            out = model(src,trg_input,src_attn_mask,trg_attn_mask,src_pad_mask,trg_pad_mask,src_pad_mask)\n",
    "            out_E = out.shape[-1] \n",
    "        \n",
    "            out = out.contiguous().view(-1,out_E)\n",
    "            trg_output = trg[1:,:]        \n",
    "            trg_output = trg_output.contiguous().view(-1)\n",
    "            \n",
    "            loss = criterion(out,trg_output)  \n",
    "            losses += loss.item()\n",
    "            \n",
    "    return losses / len(iterator)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Trainning process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "### (PARAMS)\n",
    "EPOCH = 12    # (TEMP)\n",
    "MAX_NORM = 1.0\n",
    "MODEL_NAME = 'model_simple.pt'\n",
    "\n",
    "def epoch_time(start_time, end_time):\n",
    "    elapsed_time = end_time - start_time\n",
    "    elapsed_mins = int(elapsed_time / 60)\n",
    "    elapsed_secs = int(elapsed_time - (elapsed_mins * 60))\n",
    "    return elapsed_mins, elapsed_secs\n",
    "\n",
    "# def draw_epoch_loss():\n",
    "#     pass\n",
    "\n",
    "def train():\n",
    "    best_valid_loss = float('inf')\n",
    "    train_losses = []\n",
    "    valid_losses = []\n",
    "    \n",
    "    for epoch in range(EPOCH):\n",
    "        start_time = time.time()\n",
    "        train_loss = \\\n",
    "            train_epoch(model = model, iterator = train_iterator, \\\n",
    "                        optimizer = optimizer, criterion = criterion, \\\n",
    "                        max_norm = MAX_NORM)\n",
    "        valid_loss = \\\n",
    "            eval_epoch(model = model, iterator = valid_iterator, criterion = criterion)\n",
    "        end_time = time.time()\n",
    "    \n",
    "        m,s = epoch_time(start_time, end_time)\n",
    "        print(f'Epoch: {epoch+1:02} | Time: {m}m {s}s')\n",
    "        print(f'\\tTrain Loss: {train_loss:.3f} | Train PPL: {math.exp(train_loss):7.3f}')\n",
    "        print(f'\\t Val. Loss: {valid_loss:.3f} |  Val. PPL: {math.exp(valid_loss):7.3f}')        \n",
    "        print(\"\")\n",
    "        \n",
    "        train_losses.append(train_loss)\n",
    "        valid_losses.append(valid_loss)\n",
    "        \n",
    "        if (valid_loss < best_valid_loss):\n",
    "            best_valid_loss = valid_loss\n",
    "            torch.save(model.state_dict(),MODEL_NAME)\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 01 | Time: 0m 45s\n",
      "\tTrain Loss: 3.901 | Train PPL:  49.476\n",
      "\t Val. Loss: 2.922 |  Val. PPL:  18.586\n",
      "\n",
      "Epoch: 02 | Time: 0m 45s\n",
      "\tTrain Loss: 2.614 | Train PPL:  13.654\n",
      "\t Val. Loss: 2.220 |  Val. PPL:   9.207\n",
      "\n",
      "Epoch: 03 | Time: 0m 45s\n",
      "\tTrain Loss: 1.995 | Train PPL:   7.355\n",
      "\t Val. Loss: 1.944 |  Val. PPL:   6.983\n",
      "\n",
      "Epoch: 04 | Time: 0m 46s\n",
      "\tTrain Loss: 1.595 | Train PPL:   4.929\n",
      "\t Val. Loss: 1.838 |  Val. PPL:   6.286\n",
      "\n",
      "Epoch: 05 | Time: 0m 46s\n",
      "\tTrain Loss: 1.317 | Train PPL:   3.732\n",
      "\t Val. Loss: 1.805 |  Val. PPL:   6.079\n",
      "\n",
      "Epoch: 06 | Time: 0m 46s\n",
      "\tTrain Loss: 1.106 | Train PPL:   3.021\n",
      "\t Val. Loss: 1.829 |  Val. PPL:   6.227\n",
      "\n",
      "Epoch: 07 | Time: 0m 47s\n",
      "\tTrain Loss: 0.948 | Train PPL:   2.580\n",
      "\t Val. Loss: 1.871 |  Val. PPL:   6.495\n",
      "\n",
      "Epoch: 08 | Time: 0m 46s\n",
      "\tTrain Loss: 0.824 | Train PPL:   2.280\n",
      "\t Val. Loss: 1.908 |  Val. PPL:   6.743\n",
      "\n",
      "Epoch: 09 | Time: 0m 46s\n",
      "\tTrain Loss: 0.732 | Train PPL:   2.080\n",
      "\t Val. Loss: 1.983 |  Val. PPL:   7.264\n",
      "\n",
      "Epoch: 10 | Time: 0m 45s\n",
      "\tTrain Loss: 0.660 | Train PPL:   1.935\n",
      "\t Val. Loss: 2.050 |  Val. PPL:   7.767\n",
      "\n",
      "Epoch: 11 | Time: 0m 45s\n",
      "\tTrain Loss: 0.597 | Train PPL:   1.816\n",
      "\t Val. Loss: 2.099 |  Val. PPL:   8.155\n",
      "\n",
      "Epoch: 12 | Time: 0m 45s\n",
      "\tTrain Loss: 0.548 | Train PPL:   1.730\n",
      "\t Val. Loss: 2.156 |  Val. PPL:   8.640\n",
      "\n"
     ]
    }
   ],
   "source": [
    "### trainning process\n",
    "train()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| Test Loss: 1.840 | Test PPL:   6.298 |\n"
     ]
    }
   ],
   "source": [
    "model.load_state_dict(torch.load(MODEL_NAME))\n",
    "\n",
    "test_loss = eval_epoch(model, test_iterator, criterion)\n",
    "\n",
    "print(f'| Test Loss: {test_loss:.3f} | Test PPL: {math.exp(test_loss):7.3f} |')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Use trained model to translate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Translate fcn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def greedy_decode(model, src, src_mask, max_len, start_symbol):\n",
    "    src = src.to(DEVICE)\n",
    "    src_mask = src_mask.to(DEVICE)\n",
    "\n",
    "    memory = model.encode(src, src_mask)\n",
    "    ys = torch.ones(1, 1).fill_(start_symbol).type(torch.long).to(DEVICE)\n",
    "          \n",
    "    for i in range(max_len-1):\n",
    "        \n",
    "        memory = memory.to(DEVICE)\n",
    "        memory_mask = torch.zeros(ys.shape[0], memory.shape[0]).to(DEVICE).type(torch.bool)\n",
    "        trg_mask = (model.create_trg_attn_mask(ys.size(0))\n",
    "                                    .type(torch.bool)).to(DEVICE)\n",
    "        \n",
    "        out = model.decode(ys, memory, trg_mask)\n",
    "\n",
    "        prob = model.out_linear(out)        \n",
    "\n",
    "        next_word = torch.argmax(prob[-1,0,:])\n",
    "\n",
    "        ys = torch.cat([ys,\n",
    "                        torch.ones(1, 1).type_as(src.data).fill_(next_word)], dim=0)\n",
    "        if next_word == SRC_PAD_EOS_IDX:\n",
    "            break  \n",
    "\n",
    "    return ys\n",
    "\n",
    "\n",
    "\n",
    "def translate(model, src, src_vocab,trg_vocab, src_tokenizer):\n",
    "    model.eval()\n",
    "    tokens = [SRC_PAD_INIT_IDX] + [src_vocab.stoi[tok] for tok in src] + [SRC_PAD_EOS_IDX]    \n",
    "    num_tokens = len(tokens)\n",
    "    src = (torch.LongTensor(tokens).reshape(num_tokens, 1) )\n",
    "    src_mask = (torch.zeros(num_tokens, num_tokens)).type(torch.bool)\n",
    "    \n",
    "    trg_tokens = \\\n",
    "        greedy_decode(model,  src, src_mask, max_len=num_tokens + 5, start_symbol=SRC_PAD_INIT_IDX).flatten()\n",
    "    \n",
    "    return \" \".join([trg_vocab.itos[tok] for tok in trg_tokens]).replace(\"<sos>\", \"\").replace(\"<eos>\", \"\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['ein', 'typ', 'arbeitet', 'an', 'einem', 'geb채ude', '.']\n",
      "['a', 'guy', 'works', 'on', 'a', 'building', '.']\n",
      "\n",
      " a guy is working on a building . \n"
     ]
    }
   ],
   "source": [
    "\n",
    "test_index = 8\n",
    "test_src = vars(test_data.examples[test_index])['src']\n",
    "test_trg = vars(test_data.examples[test_index])['trg']\n",
    "print(test_src)\n",
    "print(test_trg)\n",
    "print(\"\")\n",
    "\n",
    "## for dataset, input de\n",
    "result_str = translate(model, test_src,\\\n",
    "          SRC.vocab, TRG.vocab, spacy_de)\n",
    "\n",
    "print(result_str)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test bleu score & output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchtext.data.metrics import bleu_score\n",
    "\n",
    "def output_text(data, src_field, trg_field, model, device, max_len = 50): \n",
    "    with open(\"output_text.txt\",'w') as file:\n",
    "        for datum in data:\n",
    "            src = vars(datum)['src']\n",
    "            trg = vars(datum)['trg']\n",
    "            pred_trg = translate(model, src, src_field.vocab, trg_field.vocab, spacy_de) + '\\n'\n",
    "            file.write(pred_trg)\n",
    "#             print(pred_trg)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'list'>\n",
      "1000\n"
     ]
    }
   ],
   "source": [
    "print(type(test_data.examples))\n",
    "print(len(test_data.examples))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time:(s) 65.01646447181702\n"
     ]
    }
   ],
   "source": [
    "t0 = time.time()\n",
    "output_text(test_data, SRC, TRG, model, DEVICE)\n",
    "t1 = time.time() \n",
    "tspan = t1 - t0\n",
    "print(f'time:(s) {tspan}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py38",
   "language": "python",
   "name": "py38"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "toc-showmarkdowntxt": false
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
